# Hadoop 安装心得

## 搭建环境与安装

* ### 首先为hadoop创建一个纯净的环境

  为ubuntu系统新建一个用户

  ```
  sudo useradd -m hadoop -s /bin/bash
  ```

  设置密码

  ```
  sudo passwd hadoop
  ```

  增加管理员权限

  ```
  sudo adduser hadoop sudo
  ```

  以上步骤完成后即创建完毕，此时可以切换到刚刚创建的hadoop用户。

  ```
  su -i hadoop
  ```

* ### apt进行更新

  防止因为后续安装软件失败，所以需要先将ubuntu系统的软件包进行更新

  ```
  sudo apt-get update
  ```

* ### SSH安装，配置SSH无密码登录

  我们需要先安装SHH Server，执行以下命令

  ```
  sudo apt-get install openssh-server
  ```

  安装完成后通过以下命令登录到本机

  ```
  ssh localhost
  ```

  首次登录需要根据提示输入密码，就能够登录本机，并且会显示本机的ip地址 127.0.0.1

  这样我们每次输入密码即可登录到本机，而这样是比较麻烦的，所以我们配置成SSH无密码登录方便之后的登录。

  通过exit退出刚才的ssh，通过以下命令来实现无密码登录：

  ```
  cd ~/.ssh/
  ssh-keygen -t rsa 
  cat ./id_rsa.pub >> ./authorized_keys
  ```

  此时再使用ssh localhost登录就无须登录密码了。

* ### Java安装

  java在linux环境中有两个版本，一个开源版本Openjdk，还有一个oracle官方版本jdk，本次实验使用openjdk作为安装的java环境。

  首先更新软件包列表
  
  ```
  sudo apt-get update
  ```

  然后这里选择安装openjdk-8-jdk

  ```
  sudo apt-get install openjdk-8-jdk
  ```
  
  安装完成后使用以下命令可以查看java版本来检验是否安装成功：
  
  ```
  java -version
  ```
  
  #### 配置java环境变量
  
  首先在profile文件中设置好java的路径
  
  ```
  sudo vim /etc/profile
  ```
  
  ```
  export JAVA_HOME=/usr/lib/jvm/java-8-openjkd-amd64  ## 这里要注意目录要换成自己解压的jdk 目录
  export JRE_HOME=${JAVA_HOME}/jre  
  export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib  
  export PATH=${JAVA_HOME}/bin:$PATH 
  ```
  
  使环境马上生效：
  
  ```
  source /etc/profile
  ```
  
  #### 配置java环境到bashrc
  
  ```
  sudo vi ~/.bashrc
  ```
  
  在文件的最前面加上以下代码：
  
  ```
  export JAVA_HOME=/usr/lib/jvm/java-8-openjkd-amd64
  ```
  
  使环境马上生效：
  
  ```
  source ~/.bashrc
  ```
  
  这样就完成了hadoop安装前的环境配置。

- ### 下载hadoop源码并修改配置文件

  在以下网站下载最新的稳定版本的hadoop，本次实验使用的是hadoop-3.2.1

  ```
  http://mirror.bit.edu.cn/apache/hadoop/common/
  
  ```

  下载完毕后进行解压，这里把hadoop安装在/usr/local中

  ```
  sudo tar -zxf ~/下载/hadoop-3.2.1.tar.gz -C /usr/local
  cd /usr/local/
  sudo mv ./hadoop-3.2.1/ ./hadoop
  sudo chown -R hadoop ./hadoop 
  ```
  
  解压后我们可以通过以下命令查看，解压的hadoop是否可用
  
  ```
  cd /usr/local/hadoop
  ./bin/hadoop version
  ```
  
  #### 配置 Hadoop 基础框架
  
  首先修改etc/hadoop/core-site.xml文件
  
  ```
  <configuration>
  <property>
  <name>hadoop.tmp.dir</name>
  <value>file:/usr/local/hadoop/tmp/</value>
     <description>Abase for other temporary directories.</description>
        </property>
        <property> 
              <name>fs.defaultFS</name>
  <value>hdfs://localhost:9000</value>
  </property>
  </configuration>
  ```
  
  然后同样的修改配置文件hdfs-site.xml
  
  ```
  <configuration>
  <property>
  <name>dfs.replication</name>
  <value>1</value>
  </property>
  <property>
  <name>dfs.namenode.name.dir</name>
  <value>file:/usr/local/hadoop/tmp/dfs/name</value>
  </property>
  <property>
  <name>dfs.datanode.data.dir</name>
  <value>file:/usr/local/hadoop/tmp/dfs/data</value>
  </property>
  </configuration>
  ```
  
  以上配置完毕后，执行NameNode的格式化（注意在以上过程中会出现提示输入Y/N，此时需要输入大写的Y，小写的y会导致format不成功）：
  
  ```
  ./bin/hdfs namnode -format
  ```
  
  之后就可以通过命令开启namenode和datanode守护进程。
  
  ```
  ./sbin/start-dfs.sh
  ```
  
  启动成功后，可以通过命令来判断hadoop是否成功，如果有NameNode，DataNode，SecondaryNameNode以及JPS，那么表示启动成功。
  
  ```
  JPS
  54450 Jps
  5720 NameNode
  6030 SecondaryNameNode
  5823 DataNode
  ```
  
  此时就可以通过访问web页面http://localhost:9870来查看namenode以及datanode信息。
  
  通过以上步骤，即可完成hadoop的安装。

## 过程中遇到的问题

- #### hadoop的web页面访问未找到

  hadoop 3版本起使用的启动端口为9870，而2版本使用的是50070端口，这里要注意访问正确的端口，否则无法看到web页面。

- #### 格式化namenode时提示JAVA_HOME  is  not  set  and  could  not  be  found

  这是因为之前配置java环境变量出现了错误，因为我在之前已经安装好了java环境，所以这一步花费了很长的时间去检验，执行java -version可以出现java的版本，可是hadoop却找不到java，所以在经过很长时间的查找与尝试后发现，是因为没有在bashrc中添加正确的java环境，修改并让其生效后解决该问题。

- #### 使用hadoop命令提示command not found

  该问题与java找不到问题相似，需要在bashrc中添加以下命令并生效可解决该问题。

  ```
  export HADOOP_HOME=/usr/local/hadoop
  export PATH= $PATH:$HADOOP_HOME/bin
  ```

- #### hadoop安装中断，也无错误提示

  经过排查后发现，是SSH未进行无密码登录的配置，会导致hadoop安装的过程中出现错误，这是因为hadoop是通过ssh进行登录，而此时需要输入密码进行SSH登录，而hadoop过程中是不会出现输入密码的提示，所以会导致登录失败，就需要重新对SSH进行无密码的配置。

- #### JPS查看发现secondarynamenode未启动

  此时先使用sbin/stop-dfs.sh关闭进程，再次启动后发现能够正常出现，排除了错误。

- #### JPS查看发现namenode未启动

  回到xml文件的配置查看，发现是配置过程中因为手打的失误导致配置内容有错，改正后重新格式化namenode后再进行启动进程，出现namenode。

- #### 启动dfs时提示，端口被占用

  这是因为配置的端口正被其他软件使用或者之前运行的dfs未被停止造成的，此时杀死占用端口的进程即可。

  ```
  ps -e
  sudo kill 7082 #7080为要杀死的进程
  ```

- #### java not found

  在配置java时，因为粗心导致没有让变量设置生效，导致java无法找到，经过检查后改正了错误。

  ```
  source ./etc/profile
  ```
  
  



